{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quantize_best_prune.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSBsAUD9wVql"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roQOaLJVwWv2"
      },
      "source": [
        "#yolov5 import\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KZLdmDqwXzO"
      },
      "source": [
        "#Upload single quantized model (post-prune)\n",
        "\n",
        "model = torch.load(\"path_goes_here\")\n",
        "\n",
        "model_fp32 = model[\"model\"] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib3mskYzwZtC"
      },
      "source": [
        "model_fp32.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZaVuEWLwc7L"
      },
      "source": [
        "model_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-kZRQiBwtsc"
      },
      "source": [
        "model_fp32_fused = torch.quantization.fuse_modules(model_fp32, [['conv', 'relu']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOVK6KT0wuv4"
      },
      "source": [
        "model_fp32_prepared = torch.quantization.prepare(model_fp32_fused)\n",
        "input_fp32 = torch.randn(4, 1, 4, 4)\n",
        "model_fp32_prepared(input_fp32)\n",
        "model_int8 = torch.quantization.convert(model_fp32_prepared)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}